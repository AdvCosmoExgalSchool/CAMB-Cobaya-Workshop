{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import getdist.plots as gdplt\n",
    "from cobaya.model import get_model\n",
    "from cobaya import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first section, we learn the basics of Cobaya. Let's say that we have data points and want to perform a linear regression such that our model is\n",
    "$y=\\alpha x + \\beta$. We will firstly generate random data and use Cobaya to fit $\\alpha$ and $\\beta$. On top of that, let's pretend that the value (called $\\gamma$) of $y(x=1)$ is of physical interest and let's make it a derived parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "def my_model(x, alpha, beta):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose values for alpha, beta and add some Gaussian noise with amplitude epsilon\n",
    "\n",
    "alpha = 1.\n",
    "beta = 0.5\n",
    "epsilon = 0.05\n",
    "\n",
    "# Create data\n",
    "\n",
    "x_data = \n",
    "y_data = \n",
    "\n",
    "# Compute covariance (assuming data to be uncorrelated)\n",
    "\n",
    "cov = np.diag(epsilon**2*np.ones(len(x_data)))\n",
    "inv_cov = np.linalg.inv(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how our synthetic data look like as well as the theoretical, noiseless, underlying model\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(x_data,y_data,np.sqrt(np.diag(cov)), capsize=3, label=\"Data\")\n",
    "plt.plot(x_data,my_model(x_data, alpha, beta), label=\"Theoretical model\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns the Gaussian log-likelihood\n",
    "\n",
    "def my_log_likelihood(alpha, beta):\n",
    "    \n",
    "    y_theoretical = my_model(x_data, alpha, beta)\n",
    "    log_like = -0.5*(y_data-y_theoretical)@inv_cov@(y_data-y_theoretical).T\n",
    "    \n",
    "    return log_like\n",
    "\n",
    "# Create a function that returns the derived parameters\n",
    "\n",
    "def my_gamma(alpha, beta):\n",
    "    gamma = my_model(1., alpha, beta)\n",
    "    return gamma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cobaya info dictionnary\n",
    "\n",
    "info = {}\n",
    "\n",
    "info[\"likelihood\"] = {\"experiment\": my_log_likelihood}\n",
    "\n",
    "info[\"params\"] = {\n",
    "    \"alpha\": {\n",
    "        \"prior\": {\"min\": ..., \"max\": ...},\n",
    "        \"ref\": ...,\n",
    "        \"proposal\": ...,\n",
    "        \"latex\": r\"\\alpha\"\n",
    "    },\n",
    "    \"beta\": {\n",
    "        \"prior\": {\"min\": ..., \"max\": ...},\n",
    "        \"ref\": ...,\n",
    "        \"proposal\": ...,\n",
    "        \"latex\": r\"\\beta\"\n",
    "     },\n",
    "    \"gamma\": {\n",
    "        \"derived\": my_gamma,\n",
    "        \"latex\": r\"\\gamma\"\n",
    "    }\n",
    "}\n",
    "\n",
    "info[\"sampler\"] = {\n",
    "    \"mcmc\": {\n",
    "        \"Rminus1_stop\": 0.01,\n",
    "        \"max_tries\": 1000\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our cobaya model before running the mcmc\n",
    "\n",
    "model = get_model(info)\n",
    "\n",
    "# Choose a random point to perform tests\n",
    "\n",
    "random_point = model.prior.sample(ignore_external=True)[0]\n",
    "\n",
    "print(\"Our random point is:\", random_point)\n",
    "\n",
    "# Look at the log-prior, log-likelihoods, derived parameters and log-posterior\n",
    "print(\"The log-prior is:\", model.logprior(random_point))\n",
    "print(\"The log-likelihoods and derived parameters are:\",\n",
    "      model.loglikes(random_point))\n",
    "\n",
    "print(\"The log-posterior is:\", model.logpost(random_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the mcmc!\n",
    "\n",
    "updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the samples, provide right format for getdist and remove burn-in\n",
    "\n",
    "gd_sample = sampler.products(to_getdist=True, skip_samples=0.3)[\"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make triangle plot\n",
    "\n",
    "gamma_theoretical = my_gamma(alpha, beta)\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter()\n",
    "gdplot.triangle_plot(gd_sample, [\"alpha\", \"beta\", \"gamma\"], filled=True, \n",
    "                     markers={'alpha': alpha, 'beta': beta, 'gamma': gamma_theoretical})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if up to now and in the following sections we will always define the info dictionary through python, it is in practice more common to use yaml files and likelihoods defined in their own python files. I provided all the required files for the simple example we've just done. In more detail:\n",
    "\n",
    "- The model and likelihood functions we wrote above are replaced by the **simple_likelihood.py** file. Take some time to have a look at it.\n",
    "- The data and covariance matrix have already been computed and are loaded by the likelihood file.\n",
    "- The info dictionary is replaced by the simple_likelihood.yaml file. Beware some values are missing!\n",
    "\n",
    "Can you run the MCMC and find the values of $\\alpha$ and $\\beta$ I used to generate the data file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the MCMC using the yaml file and find the values of alpha and beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Oversampling, dragging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, cosmological likelihoods can be split into several pieces that can have very different execution times. Some parameters may only contribute to the fastest likelihoods and Cobaya has two different interesting techniques that allow to take advantage from those \"fast parameters\" to make the chains converge faster. Those two techniques are called \"oversampling\" and \"dragging\". \n",
    "\n",
    "In this section, we will see how to use those techniques with Cobaya. We first consider an example based on the fibonacci sequence where the likelihood takes a few seconds to run and then use the oversampling and dragging methods to speed up the convergence of the chain.\n",
    "\n",
    "Let's assume that we have two independent observations $x$ and $y$. We know that we can theoretically modeled the two observations as follow:\n",
    "\n",
    "$x = \\alpha*\\beta$ where $\\alpha$ and $\\beta$ are the two parameters we want to estimate.\n",
    "\n",
    "$y=\\Phi_n(\\alpha)$ where $\\Phi_n$ is the $n^\\rm{th}$ element of the Fibonacci sequence and depends on the initial condition which for theoretical reasons is $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the fiducial values used to generate the data\n",
    "\n",
    "alpha = 1\n",
    "beta = 2\n",
    "n = 27\n",
    "\n",
    "def fibo(n, alpha):\n",
    "    if n < 2:\n",
    "        return alpha\n",
    "    else:\n",
    "        return fibo(n-1, alpha) + fibo(n-2, alpha)\n",
    "\n",
    "# We generate the data\n",
    "x = alpha*beta\n",
    "y = fibo(n, alpha)\n",
    "y_data = np.array([x, y])\n",
    "\n",
    "# We have this covariance matrix for those observations\n",
    "cov = np.diag([1e-4, 1e7])\n",
    "inv_cov = np.linalg.inv(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then define the log-likelihood:\n",
    "\n",
    "def my_log_likelihood(alpha, beta):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the info dictionary\n",
    "\n",
    "info = {}\n",
    "\n",
    "info[\"likelihood\"] = {\"experiment\": my_log_likelihood}\n",
    "\n",
    "info[\"params\"] = {\n",
    "    \"alpha\": {\n",
    "        \"prior\": {\"min\": 0.9, \"max\": 1.1},\n",
    "        \"ref\": 1.,\n",
    "        \"proposal\": 0.0001,\n",
    "        \"latex\": r\"\\alpha\"\n",
    "    },\n",
    "    \"beta\": {\n",
    "        \"prior\": {\"min\": 0, \"max\": 10},\n",
    "        \"ref\": 2.,\n",
    "        \"proposal\": 0.01,\n",
    "        \"latex\": r\"\\beta\"\n",
    "     }\n",
    "}\n",
    "\n",
    "info[\"sampler\"] = {\n",
    "    \"mcmc\": {\n",
    "        \"Rminus1_stop\": 0.1,\n",
    "        \"max_tries\": 1000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the mcmc and time it\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "updated_info, sampler = run(info)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the oversampling and dragging methods to speed up the convergence. \n",
    "\n",
    "**Task:** \n",
    "Create two different likelihoods for the two observations $x$ and $y$ and re-run the MCMC. By default, Cobaya will automatically detect if one likelihood is faster than the other and will apply the oversampling method if that is relevant. Then, to use the dragging method instead, set the 'drag' flag to True in the 'mcmc' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Interaction with CAMB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Cobaya, you can create theory classes which can then be used by the likelihoods you create to compute relevant quantities to model the observations you want to fit. In the case of the CMB for instance, CAMB is used to model the power spectra which can then be compared to the observations inside your likelihoods. In Cobaya, a CAMB wrapper has already been implemented so that you can directly specify 'camb' in the 'theory' field of the info dictionary. In this section, we will see in more details how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define cosmological parameters here\n",
    "\n",
    "H0 = 67.5\n",
    "ombh2 = 0.02242\n",
    "omch2 = 0.11933\n",
    "tau = 0.0561\n",
    "As = 2.105e-9\n",
    "ns = 0.9665"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task :**\n",
    "Use camb to generate some synthetic data (for instance, only TT power spectra with lmax=2000). In order to gain some execution time, you can specify:\n",
    "- AccuracyBoost=0.6\n",
    "- NonLinear='NonLinear_none'\n",
    "when setting parameters. Those degraded options will speed up the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a covariance matrix. Let's assume a full-sky cosmic-variance limited survey\n",
    "\n",
    "ls = np.arange(powers['total'].shape[0])[2:lmax]\n",
    "cl_tt = powers['total'][2:lmax,0]\n",
    "cov = np.diag(2/(2*(ls+1))*cl_tt**2)\n",
    "inv_cov = np.linalg.inv(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sigma = np.diag(np.sqrt(cov))\n",
    "plt.figure()\n",
    "plt.fill_between(ls, cl_tt-sigma, cl_tt+sigma, color='C0', alpha=1)\n",
    "plt.fill_between(ls, cl_tt-2*sigma, cl_tt+2*sigma, color='C0', alpha=0.5)\n",
    "plt.xlabel(r\"$\\ell$\", fontsize=14)\n",
    "plt.ylabel(r\"$C_\\ell^{TT}$\", fontsize=14)\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(ls, cl_tt-sigma, cl_tt+sigma, color='C0', alpha=1)\n",
    "plt.fill_between(ls, cl_tt-2*sigma, cl_tt+2*sigma, color='C0', alpha=0.5)\n",
    "plt.semilogx()\n",
    "plt.xlabel(r\"$\\ell$\", fontsize=14)\n",
    "plt.ylabel(r\"$C_\\ell^{TT}$\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a Likelihood class. Note that the logp method must always be defined \n",
    "# while initialize and get_requirements are optional\n",
    "\n",
    "from cobaya.likelihood import Likelihood\n",
    "\n",
    "class my_likelihood_class(Likelihood):\n",
    "\n",
    "    def initialize(self):\n",
    "        self.data = ...\n",
    "        self.inv_covmat = ...\n",
    "        self.lmin = 2\n",
    "        self.lmax = lmax\n",
    "        \n",
    "    # The get_requirements method is used to specify what the likelihood needs the theory class to provide\n",
    "    # Here we need CAMB to provide the TT power spectra up to l=lmax\n",
    "    def get_requirements(self):\n",
    "        return {'Cl': {'tt': lmax}}\n",
    "\n",
    "    # Here we compute the log-likelihood\n",
    "    def logp(self, **params_values):\n",
    "        cls = self.provider.get_Cl(ell_factor=True, units=\"1\") \n",
    "        # This is known because we requested it in get_requirements\n",
    "        \n",
    "        ...\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we only want to sample w, the equation of state parameter of dark energy\n",
    "\n",
    "info = {}\n",
    "\n",
    "info['theory'] = {'camb': \n",
    "                     {'extra_args': {\n",
    "                         'ombh2': ombh2,\n",
    "                         'omch2': omch2,\n",
    "                         'tau': tau,\n",
    "                         'As': As,\n",
    "                         'ns': ns,\n",
    "                         'H0': H0,\n",
    "                         'AccuracyBoost': 0.6,\n",
    "                         'NonLinear': 'NonLinear_none',\n",
    "                         'lmax': lmax,\n",
    "                         'dark_energy_model': 'DarkEnergyPPF'\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "\n",
    "info[\"likelihood\"] = ...\n",
    "\n",
    "info[\"params\"] = {\n",
    "    \"w\": {\n",
    "        \"prior\": {\"min\": -3, \"max\": 3},\n",
    "        \"ref\": -1,\n",
    "        \"proposal\": 0.001,\n",
    "        \"latex\": r\"w\"\n",
    "    }\n",
    "}\n",
    "\n",
    "info[\"sampler\"] = {\n",
    "    \"mcmc\": {\n",
    "        # We modify the convergence criteria so that the run is not too long\n",
    "        \"Rminus1_stop\": 0.25,\n",
    "        \"Rminus1_cl_stop\": 0.5,\n",
    "        \"max_tries\": 1000\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your information (also useful for following sections), this is what CAMB can provide\n",
    "\n",
    "model = get_model(info)\n",
    "\n",
    "# Those are the parameters that CAMB can provide (in a likelihood class for instance)\n",
    "print(model.theory['camb'].get_can_provide_params())\n",
    "\n",
    "# Those are the functions of CAMB that can be called (in a likelihood class for instance)\n",
    "print(model.theory['camb'].get_can_provide_methods())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sample = sampler.products(to_getdist=True, skip_samples=0.3)[\"sample\"]\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(width_inch=5)\n",
    "gdplot.plot_1d(gd_sample, \"w\", title_limit=1)\n",
    "gdplot.add_x_marker(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 : Use cobaya's included likelihoods. Example: Planck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cobaya has a number of already implemented likelihoods. For instance, you can directly used the latest Planck likelihood without any effort. In particular, the calibration and nuisance parameters will be automatically added, together with the priors and proposal values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cobaya info dictionnary\n",
    "\n",
    "info = {}\n",
    "\n",
    "info['theory'] = {'camb': \n",
    "                     {'extra_args': {\n",
    "                         'ombh2': ombh2,\n",
    "                         'omch2': omch2,\n",
    "                         'tau': tau,\n",
    "                         'As': As,\n",
    "                         'ns': ns,\n",
    "                         'H0': H0,\n",
    "                         'AccuracyBoost': 0.6,\n",
    "                         'NonLinear': 'NonLinear_none',\n",
    "                         'lmax': lmax,\n",
    "                         'dark_energy_model': 'DarkEnergyPPF'\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "\n",
    "info[\"likelihood\"] = {'planck_NPIPE_highl_CamSpec.TTTEEE': None}\n",
    "\n",
    "info[\"params\"] = {\n",
    "    \"w\": {\n",
    "        \"prior\": {\"min\": -3, \"max\": 0},\n",
    "        \"ref\": -1.,\n",
    "        \"proposal\": 0.001,\n",
    "        \"latex\": r\"w_0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "covmat = np.load(\"covmat_w_Planck.npy\")\n",
    "\n",
    "info[\"sampler\"] = {\n",
    "    \"mcmc\": {\n",
    "        \"Rminus1_stop\": 0.3,\n",
    "        \"Rminus1_cl_stop\": 0.5,\n",
    "        \"max_tries\": 1000,\n",
    "        \"learn_proposal_Rminus1_max\": 0.4,\n",
    "        \"covmat\": covmat,\n",
    "        \"covmat_params\": ['w','A_planck', 'amp_143', 'amp_217', 'amp_143x217', 'n_143', 'n_217', 'n_143x217', 'calTE', 'calEE']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attention to the fact that Cobaya is automatically using oversampling!\n",
    "\n",
    "updated_info, sampler = run(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sample = sampler.products(to_getdist=True, skip_samples=0.3)[\"sample\"]\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter()\n",
    "gdplot.triangle_plot(gd_sample, \n",
    "    ['w','A_planck', 'amp_143', 'amp_217', 'amp_143x217', 'n_143', 'n_217', 'n_143x217', 'calTE', 'calEE'], \n",
    "    filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Write your own (more advanced) likelihood class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this more advanced section, we will use what we have used so far to put some constraints on four parameters, namely: \n",
    "- the Hubble constant $H_0$\n",
    "- the dark matter density $\\omega_c=\\Omega_ch^2$\n",
    "- the dark energy equation of state CPL parameters $w_0$ and $w_a$ where $w(a) = w_0 + (1-a)w_a$\n",
    "\n",
    "We will use several observations to constrain those parameters and hence perform a multi probe analysis. The probe we will consider are:\n",
    "- a (very) approximate CMB likelihood\n",
    "- a (very) approximate BAO likelihood\n",
    "- a local measurement of $H_0$\n",
    "\n",
    "**Probe 1: CMB**\n",
    "\n",
    "We could use the Planck likelihood as it is already implemented in Cobaya, however computing the power spectra through CAMB takes too much time for the purpose of this section. We assume that the CMB likelihood consists in two quantities\n",
    "- the angular scale $\\theta_\\star=1.04109 \\pm 0.0003$ which is related to the position of the first peak in the CMB power spectrum\n",
    "- the redshift of recombination $z_\\star = 1089.95 \\pm 0.27$\n",
    "\n",
    "**Task :**\n",
    "Implement this likelihood and run the MCMC for the four parameters mentioned above. Show the triangle plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMB(Likelihood):\n",
    "\n",
    "    def initialize(self):\n",
    "        \n",
    "\n",
    "    def get_requirements(self):\n",
    "        \n",
    "\n",
    "    def logp(self, **params_values):\n",
    "        \n",
    "\n",
    "info = {}\n",
    "\n",
    "info['theory'] = {'camb': \n",
    "                     {'extra_args': {\n",
    "                         ...\n",
    "                         'dark_energy_model': 'DarkEnergyPPF'\n",
    "                         }\n",
    "                     }\n",
    "                 }\n",
    "\n",
    "info[\"likelihood\"] = ...\n",
    "\n",
    "info[\"params\"] = ...\n",
    "\n",
    "info[\"sampler\"] = {\n",
    "    \"mcmc\": {\n",
    "        \"Rminus1_stop\": 0.1,\n",
    "        \"max_tries\": 1000,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probe 2: BAO**\n",
    "\n",
    "We use data from \"DESI 2024 VI: Cosmological Constraints from the Measurements of Baryon Acoustic Oscillations\". We assume all the measurements to be independent. \n",
    "\n",
    "Here are the measurements we will use:\n",
    "- $D_V/r_d(z=0.295) = 7.93 \\pm 0.15$\n",
    "- $D_V/r_d(z=1.491) = 26.07 \\pm 0.67$\n",
    "\n",
    "- $D_M/r_d(z=0.510) = 13.62 \\pm 0.25$\n",
    "- $D_M/r_d(z=0.706) = 16.85 \\pm 0.32$\n",
    "- $D_M/r_d(z=0.930) = 21.71 \\pm 0.28$\n",
    "- $D_M/r_d(z=1.317) = 27.79 \\pm 0.69$\n",
    "- $D_M/r_d(z=2.330) = 39.71 \\pm 0.94$\n",
    "\n",
    "- $D_H/r_d(z=0.510) = 20.98 \\pm 0.61$\n",
    "- $D_H/r_d(z=0.706) = 20.08 \\pm 0.60$\n",
    "- $D_H/r_d(z=0.930) = 17.88 \\pm 0.35$\n",
    "- $D_H/r_d(z=1.317) = 13.82 \\pm 0.42$\n",
    "- $D_H/r_d(z=2.330) = 8.52 \\pm 0.17$\n",
    "\n",
    "**Task:** \n",
    "\n",
    "Implement this likelihood, run the MCMC and make the triangle plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probe 3: Local measurement of $H_0$**\n",
    "\n",
    "We finally add a last measurement which is based on the local measurement of $H_0$ with the distance-ladder method. The latest measurement (https://arxiv.org/abs/2112.04510) is \n",
    "\n",
    "$H_0 = 73.04 \\pm 1.04$ and can be added as a Gaussian likelihood.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Implement this likelihood and run the MCMC with the combination of the three likelihoods (CMB + BAO + local H0), make the triangle plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus section: try using Cobaya for a simple model relevant to your research area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
